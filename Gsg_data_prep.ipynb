{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the modules\n",
    "import glob\n",
    "import os\n",
    "import tabula\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a list contaning all the df obtained from pdf structure: [[df_1,_df_2], [df_1,df_2]]\n",
    "#names = [str(i) for i in range(1,3)]\n",
    "#pdfs = []\n",
    "#for pdf in names:\n",
    " #   file_name = \"%s.pdf\" % pdf\n",
    "  #  df =  tabula.read_pdf(file_name, pages = 2)\n",
    "#pdfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir= \"C:\\\\Users\\\\bhaveshthakkar\\\\Study\\\\Files\\\\\"\n",
    "pdf_files = glob.glob(os.path.join(my_dir, '*.pdf'))\n",
    "\n",
    "all_pdfs = []\n",
    "for pdfs in pdf_files:\n",
    "    file_name = pdfs\n",
    "    df =  tabula.read_pdf(file_name, pages = 2)\n",
    "    all_pdfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting lists which has only three data frames  (length of orignal list is more than 100 of which majority sublists\n",
    "# contains 3 data frames)\n",
    "new_list = []\n",
    "for i in all_pdfs:\n",
    "    if len(i) == 3:\n",
    "        new_list.append(i)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To concat all the data frames in each sublists\n",
    "all_df_1 = []\n",
    "for i in new_list:\n",
    "    all_df_1.append(pd.concat([i[0],i[1],i[2]], axis = 0, ignore_index = True ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating on all the data frames in the previously concated list of dfs  \n",
    "all_df_final = []\n",
    "\n",
    "for i in range(len(all_df_1)):\n",
    "    df_1 = all_df_1[i][all_df_t[i][\"Unnamed: 0\"].notna()]\n",
    "    df_1 = df_1.iloc[~df_1.index.isin([1,2])]\n",
    "    df_2 = df_1.iloc[:,0:3]\n",
    "    df_2 = df_2.T\n",
    "    df_2.columns = df_2.iloc[0]\n",
    "    df_2 = df_2.iloc[1:]\n",
    "    df_2 = df_2.fillna(method = \"bfill\")\n",
    "    df_2 = df_2.iloc[[0]]\n",
    "    df_2 = df_2.iloc[:,0:5]\n",
    "    df_3 = df_1.iloc[:,4:].dropna(how = \"all\")\n",
    "    df_3.columns = df_3.iloc[0]\n",
    "    df_3 = df_3.iloc[1:]\n",
    "    df_1 = pd.concat([df_2, df_3], axis = 1)\n",
    "    df_1 = df_1.fillna(method = \"ffill\").iloc[1:]\n",
    "    all_df_final.append(df_1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list from the all_pdfs for sublists with 3 dfs each\n",
    "new_list_2 = []\n",
    "for i in all_pdfs:\n",
    "    if len(i) != 3:\n",
    "        new_list_2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     Unnamed: 0                         Graduate Group Information  Unnamed: 1\n",
       " 0  Organization  School of Criminology and Criminal Justice Gra...         NaN\n",
       " 1  Contact Name                                     Sarah Lockwood         NaN\n",
       " 2         Email                           lockwood.s@husky.neu.edu         NaN\n",
       " 3  Award Amount                                               $210         NaN,\n",
       "           Unnamed: 0                                  Event Information  \\\n",
       " 0         Event Name  Research and Identity Lunch Roundtable Discussion   \n",
       " 1         Event Date                                         11/21/2019   \n",
       " 2  Event Description  Thepurposeofthiseventistogatherstudentsandfacu...   \n",
       " \n",
       "    Unnamed: 1  \n",
       " 0         NaN  \n",
       " 1         NaN  \n",
       " 2         NaN  ,\n",
       "    Transaction Detail Unnamed: 0 Unnamed: 1 Unnamed: 2   Unnamed: 3 Unnamed: 4\n",
       " 0  Transaction Detail        NaN        NaN        NaN          NaN        NaN\n",
       " 1                From         To        NaN        NaN          NaN        NaN\n",
       " 2                From         To        NaN        NaN          NaN        NaN\n",
       " 3               Index    Account      Index    Account  Description     Amount\n",
       " 4               Index    Account      Index    Account  Description     Amount\n",
       " 5              801538      73000     800228      74320         Food       $210\n",
       " 6                 NaN        NaN        NaN        NaN          NaN        NaN\n",
       " 7                 NaN        NaN        NaN        NaN          NaN        NaN\n",
       " 8                 NaN        NaN        NaN        NaN          NaN        NaN,\n",
       "    Transaction Detail\n",
       " 0  Transaction Detail,\n",
       "    From\n",
       " 0  From,\n",
       "    To\n",
       " 0  To,\n",
       "    Index\n",
       " 0  Index,\n",
       "    Account\n",
       " 0  Account,\n",
       "    Index\n",
       " 0  Index,\n",
       "    Account\n",
       " 0  Account,\n",
       "    Description\n",
       " 0  Description,\n",
       "    Amount\n",
       " 0  Amount]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concating all dfs in each sublists\n",
    "all_df_2 = []\n",
    "for i in new_list_2:\n",
    "    all_df_2.append(pd.concat(i, axis = 0, ignore_index = True ).iloc[:,0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating on dfs inside he sublist\n",
    "final_list = []\n",
    "\n",
    "for i in range(len(all_df_2)):\n",
    "    df = all_df_2[i].drop(columns = [\"From\"]).dropna(how = \"all\").reset_index(drop = True)\n",
    "    df = df[~df[\"Transaction Detail\"].isin([\"Transaction Detail\", \"From\"])]\n",
    "    df = df.T\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.reset_index(drop = True).drop(columns = [\"Account\", \"Account\"]).iloc[1:,:]#.fillna(method = \"bfill\")\n",
    "    df_1 = df.iloc[0:3,:].dropna(axis = 1, how = \"all\").fillna(method = \"bfill\").iloc[[0],:].rename(columns = {\"73000\":\"index\"})\n",
    "    df_2 = df.iloc[:,7:].dropna(how = \"all\")\n",
    "    df_2 = df_2.T.drop(columns = 4).reset_index(drop = True)\n",
    "    df = pd.concat([df_1,df_2], axis = 1).drop(columns = [\"Email\", \"Contact Name\"])\n",
    "    final_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating CSV for all the data frame in list\n",
    "# Looping over all dfs to create a concate df. \n",
    "# Did not concat all dfs before exporting into CSV as there were few data frames which had diffrent number on columns\n",
    "\n",
    "writer = pd.ExcelWriter('final_1.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Add the first dataframe to the worksheet.\n",
    "all_df_final[0].to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "offset = len(all_df_final[0]) + 1  # Add extra row for column header.\n",
    "\n",
    "# Add the other dataframes.\n",
    "for df in all_df_final:\n",
    "    # Write the datafram without a column header or index.\n",
    "    df.to_excel(writer, sheet_name='Sheet1', startrow=offset,\n",
    "                header=False, index=False)\n",
    "\n",
    "    offset += len(df)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('final_2.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Add the first dataframe to the worksheet.\n",
    "final_list[0].to_excel(writer, sheet_name='Sheet1', index=True)\n",
    "\n",
    "offset = len(final_list[0]) + 1  # Add extra row for column header.\n",
    "\n",
    "# Add the other dataframes.\n",
    "for df in all_df_final:\n",
    "    # Write the datafram without a column header or index.\n",
    "    df.to_excel(writer, sheet_name='Sheet1', startrow=offset,\n",
    "                header=False, index=False)\n",
    "\n",
    "    offset += len(df)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
